{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "070a050a-44d1-42c2-b274-c8c180a2a0ba",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.006082,
     "end_time": "2024-03-20T19:40:18.606305",
     "exception": false,
     "start_time": "2024-03-20T19:40:18.600223",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fcbb4d-aa04-4e1a-9aee-0053c559e157",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.005328,
     "end_time": "2024-03-20T19:40:18.622153",
     "exception": false,
     "start_time": "2024-03-20T19:40:18.616825",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This notebook is a template notebook that is intended to be run across different parameters.\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b237f234-dc98-43e9-8ff5-8922c410c377",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.005284,
     "end_time": "2024-03-20T19:40:18.632832",
     "exception": false,
     "start_time": "2024-03-20T19:40:18.627548",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70413318-1f5e-4d58-b1a2-cb4f01c13e86",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-03-20T19:40:18.645184Z",
     "iopub.status.busy": "2024-03-20T19:40:18.644983Z",
     "iopub.status.idle": "2024-03-20T19:40:19.696748Z",
     "shell.execute_reply": "2024-03-20T19:40:19.696175Z"
    },
    "papermill": {
     "duration": 1.060158,
     "end_time": "2024-03-20T19:40:19.698297",
     "exception": false,
     "start_time": "2024-03-20T19:40:18.638139",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "from proj import conf\n",
    "from proj.utils import llm_pairwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f78fd18-86b7-40b9-b80e-a8b18d001682",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.034361,
     "end_time": "2024-03-20T19:40:19.738738",
     "exception": false,
     "start_time": "2024-03-20T19:40:19.704377",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Settings/paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a3ceca-1480-45b0-b04d-cb402ff95abf",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-03-20T19:40:19.752681Z",
     "iopub.status.busy": "2024-03-20T19:40:19.752432Z",
     "iopub.status.idle": "2024-03-20T19:40:19.755404Z",
     "shell.execute_reply": "2024-03-20T19:40:19.754908Z"
    },
    "papermill": {
     "duration": 0.011384,
     "end_time": "2024-03-20T19:40:19.756586",
     "exception": false,
     "start_time": "2024-03-20T19:40:19.745202",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Input manuscript\n",
    "REPO = None\n",
    "\n",
    "INPUT_FILE = None\n",
    "OUTPUT_FILE = None\n",
    "\n",
    "# Model and its parameters\n",
    "LLM_JUDGE = None\n",
    "TEMPERATURE = None\n",
    "MAX_TOKENS = 2000\n",
    "SEED_INIT = 0\n",
    "\n",
    "# Evaluation parameters\n",
    "N_REPS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbf3522f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T19:40:19.768887Z",
     "iopub.status.busy": "2024-03-20T19:40:19.768758Z",
     "iopub.status.idle": "2024-03-20T19:40:19.771412Z",
     "shell.execute_reply": "2024-03-20T19:40:19.770933Z"
    },
    "papermill": {
     "duration": 0.010112,
     "end_time": "2024-03-20T19:40:19.772493",
     "exception": false,
     "start_time": "2024-03-20T19:40:19.762381",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "REPO = \"pivlab/manubot-ai-editor-code-test-biochatter-manuscript\"\n",
    "INPUT_FILE = \"/home/miltondp/projects/others/manubot/manubot-ai-editor-code/base/results/paragraph_match/biochatter-manuscript--gpt-3.5-turbo.pkl\"\n",
    "OUTPUT_FILE = \"/home/miltondp/projects/others/manubot/manubot-ai-editor-code/base/results/llm_pairwise/biochatter-manuscript--gpt-3.5-turbo--mistral_7b-instruct-fp16.pkl\"\n",
    "LLM_JUDGE = \"mistral:7b-instruct-fp16\"\n",
    "TEMPERATURE = 0.5\n",
    "MAX_TOKENS = 2000\n",
    "SEED_INIT = 0\n",
    "N_REPS = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2245c8bd-63ca-489c-aad5-91a4b57d5e37",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-03-20T19:40:19.784885Z",
     "iopub.status.busy": "2024-03-20T19:40:19.784760Z",
     "iopub.status.idle": "2024-03-20T19:40:19.789303Z",
     "shell.execute_reply": "2024-03-20T19:40:19.788762Z"
    },
    "papermill": {
     "duration": 0.012157,
     "end_time": "2024-03-20T19:40:19.790535",
     "exception": false,
     "start_time": "2024-03-20T19:40:19.778378",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/miltondp/projects/others/manubot/manubot-ai-editor-code/base/results/llm_cache')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf.common.LLM_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "display(conf.common.LLM_CACHE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42b83b5-84b7-45ff-88ee-3651aa5c9c55",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.005742,
     "end_time": "2024-03-20T19:40:19.802017",
     "exception": false,
     "start_time": "2024-03-20T19:40:19.796275",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Load paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1d1f476-f5b5-4d1c-9c3a-822e9bef4b27",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-03-20T19:40:19.811802Z",
     "iopub.status.busy": "2024-03-20T19:40:19.811590Z",
     "iopub.status.idle": "2024-03-20T19:40:19.815204Z",
     "shell.execute_reply": "2024-03-20T19:40:19.814683Z"
    },
    "papermill": {
     "duration": 0.008916,
     "end_time": "2024-03-20T19:40:19.816104",
     "exception": false,
     "start_time": "2024-03-20T19:40:19.807188",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(INPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e3db6e2-f267-4d60-8ff3-703698a09f88",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-03-20T19:40:19.823286Z",
     "iopub.status.busy": "2024-03-20T19:40:19.822933Z",
     "iopub.status.idle": "2024-03-20T19:40:19.826658Z",
     "shell.execute_reply": "2024-03-20T19:40:19.826159Z"
    },
    "papermill": {
     "duration": 0.00825,
     "end_time": "2024-03-20T19:40:19.827461",
     "exception": false,
     "start_time": "2024-03-20T19:40:19.819211",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc6a365d-59f5-4537-9fd7-869ee4156046",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-03-20T19:40:19.834712Z",
     "iopub.status.busy": "2024-03-20T19:40:19.834507Z",
     "iopub.status.idle": "2024-03-20T19:40:19.842537Z",
     "shell.execute_reply": "2024-03-20T19:40:19.842029Z"
    },
    "papermill": {
     "duration": 0.012695,
     "end_time": "2024-03-20T19:40:19.843347",
     "exception": false,
     "start_time": "2024-03-20T19:40:19.830652",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>original</th>\n",
       "      <th>modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>Current-generation Large Language Models (LLMs...</td>\n",
       "      <td>Large Language Models (LLMs) have generated si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>introduction</td>\n",
       "      <td>Despite technological advances, understanding ...</td>\n",
       "      <td>Despite technological advances, understanding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>introduction</td>\n",
       "      <td>Large Language Models (LLMs) of the current ge...</td>\n",
       "      <td>The latest generation of Large Language Models...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>introduction</td>\n",
       "      <td>Computational biomedicine involves many tasks ...</td>\n",
       "      <td>Computational biomedicine encompasses various ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>results</td>\n",
       "      <td>The framework is designed to be modular: any o...</td>\n",
       "      <td>The framework is designed to be modular, allow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        section                                           original  \\\n",
       "0      abstract  Current-generation Large Language Models (LLMs...   \n",
       "1  introduction  Despite technological advances, understanding ...   \n",
       "2  introduction  Large Language Models (LLMs) of the current ge...   \n",
       "3  introduction  Computational biomedicine involves many tasks ...   \n",
       "4       results  The framework is designed to be modular: any o...   \n",
       "\n",
       "                                            modified  \n",
       "0  Large Language Models (LLMs) have generated si...  \n",
       "1  Despite technological advances, understanding ...  \n",
       "2  The latest generation of Large Language Models...  \n",
       "3  Computational biomedicine encompasses various ...  \n",
       "4  The framework is designed to be modular, allow...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "589fb328-d62a-4573-8177-a9dbd1e495b0",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-03-20T19:40:19.850898Z",
     "iopub.status.busy": "2024-03-20T19:40:19.850526Z",
     "iopub.status.idle": "2024-03-20T19:40:19.854433Z",
     "shell.execute_reply": "2024-03-20T19:40:19.853944Z"
    },
    "papermill": {
     "duration": 0.008574,
     "end_time": "2024-03-20T19:40:19.855227",
     "exception": false,
     "start_time": "2024-03-20T19:40:19.846653",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Current-generation Large Language Models (LLMs) have stirred enormous interest in recent months, yielding great potential for accessibility and automation, while simultaneously posing significant challenges and risk of misuse. To facilitate interfacing with LLMs in the biomedical space, while at the same time safeguarding their functionalities through sensible constraints, we propose a dedicated, open-source framework: BioChatter. Based on open-source software packages, we synergise the many functionalities that are currently developing around LLMs, such as knowledge integration / retrieval-augmented generation, model chaining, and benchmarking, resulting in an easy-to-use and inclusive framework for application in many use cases of biomedicine. We focus on robust and user-friendly implementation, including ways to deploy privacy-preserving local open-source LLMs. We demonstrate use cases via two multi-purpose web apps ([https://chat.biocypher.org](https://chat.biocypher.org)), and provide documentation, support, and an open community.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][\"original\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b5fba85-97aa-4051-b755-c45f8dbf2448",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-03-20T19:40:19.862756Z",
     "iopub.status.busy": "2024-03-20T19:40:19.862565Z",
     "iopub.status.idle": "2024-03-20T19:40:19.866537Z",
     "shell.execute_reply": "2024-03-20T19:40:19.866041Z"
    },
    "papermill": {
     "duration": 0.008745,
     "end_time": "2024-03-20T19:40:19.867356",
     "exception": false,
     "start_time": "2024-03-20T19:40:19.858611",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Large Language Models (LLMs) have generated significant interest due to their potential for accessibility and automation in various fields, including biomedicine. However, they also present challenges and risks of misuse. In this paper, we address the need for a framework to interface with LLMs in the biomedical domain while ensuring their safe and effective use. To meet this need, we introduce BioChatter, an open-source framework that integrates various functionalities of LLMs, such as knowledge integration, retrieval-augmented generation, model chaining, and benchmarking. By leveraging open-source software packages, we have developed a user-friendly and versatile platform that can be applied across a range of biomedicine use cases. Our focus is on implementing robust and privacy-preserving local open-source LLMs. We showcase the utility of BioChatter through two multi-purpose web apps available at [https://chat.biocypher.org](https://chat.biocypher.org) and provide comprehensive documentation, support, and a vibrant open community.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][\"modified\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9291eef4-d5ee-4d89-b34d-997501f0cd0b",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.003375,
     "end_time": "2024-03-20T19:40:19.874179",
     "exception": false,
     "start_time": "2024-03-20T19:40:19.870804",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b7e80bd-f678-4047-b0f6-3c4e55de4767",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-03-20T19:40:19.882008Z",
     "iopub.status.busy": "2024-03-20T19:40:19.881619Z",
     "iopub.status.idle": "2024-03-20T19:40:28.960691Z",
     "shell.execute_reply": "2024-03-20T19:40:28.959982Z"
    },
    "papermill": {
     "duration": 9.084393,
     "end_time": "2024-03-20T19:40:28.961988",
     "exception": false,
     "start_time": "2024-03-20T19:40:19.877595",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are an expert copyeditor with ample experience in scientific writing. You are assessing the quality of two versions of a paragraph from the Abstract of a scientific article.\n",
      "Human: Evaluate the quality of the following paragraph by writing a list with positive (if any) and/or negative (if any) aspects on the following areas: 1) has a clear sentence structure, 2) is easy to follow, 3) is correct in grammar, 4) has no spelling errors.\n",
      "\n",
      "Paragraph A: Current-generation Large Language Models (LLMs) have stirred enormous interest in recent months, yielding great potential for accessibility and automation, while simultaneously posing significant challenges and risk of misuse. To facilitate interfacing with LLMs in the biomedical space, while at the same time safeguarding their functionalities through sensible constraints, we propose a dedicated, open-source framework: BioChatter. Based on open-source software packages, we synergise the many functionalities that are currently developing around LLMs, such as knowledge integration / retrieval-augmented generation, model chaining, and benchmarking, resulting in an easy-to-use and inclusive framework for application in many use cases of biomedicine. We focus on robust and user-friendly implementation, including ways to deploy privacy-preserving local open-source LLMs. We demonstrate use cases via two multi-purpose web apps ([https://chat.biocypher.org](https://chat.biocypher.org)), and provide documentation, support, and an open community.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are an expert copyeditor with ample experience in scientific writing. You are assessing the quality of two versions of a paragraph from the Abstract of a scientific article.\n",
      "Human: Evaluate the quality of the following paragraph by writing a list with positive (if any) and/or negative (if any) aspects on the following areas: 1) has a clear sentence structure, 2) is easy to follow, 3) is correct in grammar, 4) has no spelling errors.\n",
      "\n",
      "Paragraph A: Current-generation Large Language Models (LLMs) have stirred enormous interest in recent months, yielding great potential for accessibility and automation, while simultaneously posing significant challenges and risk of misuse. To facilitate interfacing with LLMs in the biomedical space, while at the same time safeguarding their functionalities through sensible constraints, we propose a dedicated, open-source framework: BioChatter. Based on open-source software packages, we synergise the many functionalities that are currently developing around LLMs, such as knowledge integration / retrieval-augmented generation, model chaining, and benchmarking, resulting in an easy-to-use and inclusive framework for application in many use cases of biomedicine. We focus on robust and user-friendly implementation, including ways to deploy privacy-preserving local open-source LLMs. We demonstrate use cases via two multi-purpose web apps ([https://chat.biocypher.org](https://chat.biocypher.org)), and provide documentation, support, and an open community.\n",
      "AI: \n",
      "Positive aspects:\n",
      "1) The paragraph has a clear sentence structure.\n",
      "2) It is easy to follow the main idea of the paragraph.\n",
      "3) There are no spelling errors.\n",
      "4) The language used in the paragraph is appropriate for a scientific audience.\n",
      "5) The paragraph provides specific examples of BioChatter's use cases and demonstrates its functionality through web apps.\n",
      "6) The paragraph highlights the importance of privacy-preserving local open-source LLMs, which is relevant to many biomedical applications.\n",
      "\n",
      "Negative aspects:\n",
      "1) There are some instances where sentence structure could be improved for clarity.\n",
      "2) Some phrases could be rephrased for better flow and readability.\n",
      "3) The paragraph could benefit from more concise language in certain sections.\n",
      "Human: Evaluate the quality of the following paragraph by writing a list with positive (if any) and/or negative (if any) aspects on the following areas: 1) has a clear sentence structure, 2) is easy to follow, 3) is correct in grammar, 4) has no spelling errors.\n",
      "\n",
      "Paragraph 1: Large Language Models (LLMs) have generated significant interest due to their potential for accessibility and automation in various fields, including biomedicine. However, they also present challenges and risks of misuse. In this paper, we address the need for a framework to interface with LLMs in the biomedical domain while ensuring their safe and effective use. To meet this need, we introduce BioChatter, an open-source framework that integrates various functionalities of LLMs, such as knowledge integration, retrieval-augmented generation, model chaining, and benchmarking. By leveraging open-source software packages, we have developed a user-friendly and versatile platform that can be applied across a range of biomedicine use cases. Our focus is on implementing robust and privacy-preserving local open-source LLMs. We showcase the utility of BioChatter through two multi-purpose web apps available at [https://chat.biocypher.org](https://chat.biocypher.org) and provide comprehensive documentation, support, and a vibrant open community.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are an expert copyeditor with ample experience in scientific writing. You are assessing the quality of two versions of a paragraph from the Abstract of a scientific article.\n",
      "Human: Evaluate the quality of the following paragraph by writing a list with positive (if any) and/or negative (if any) aspects on the following areas: 1) has a clear sentence structure, 2) is easy to follow, 3) is correct in grammar, 4) has no spelling errors.\n",
      "\n",
      "Paragraph A: Current-generation Large Language Models (LLMs) have stirred enormous interest in recent months, yielding great potential for accessibility and automation, while simultaneously posing significant challenges and risk of misuse. To facilitate interfacing with LLMs in the biomedical space, while at the same time safeguarding their functionalities through sensible constraints, we propose a dedicated, open-source framework: BioChatter. Based on open-source software packages, we synergise the many functionalities that are currently developing around LLMs, such as knowledge integration / retrieval-augmented generation, model chaining, and benchmarking, resulting in an easy-to-use and inclusive framework for application in many use cases of biomedicine. We focus on robust and user-friendly implementation, including ways to deploy privacy-preserving local open-source LLMs. We demonstrate use cases via two multi-purpose web apps ([https://chat.biocypher.org](https://chat.biocypher.org)), and provide documentation, support, and an open community.\n",
      "AI: \n",
      "Positive aspects:\n",
      "1) The paragraph has a clear sentence structure.\n",
      "2) It is easy to follow the main idea of the paragraph.\n",
      "3) There are no spelling errors.\n",
      "4) The language used in the paragraph is appropriate for a scientific audience.\n",
      "5) The paragraph provides specific examples of BioChatter's use cases and demonstrates its functionality through web apps.\n",
      "6) The paragraph highlights the importance of privacy-preserving local open-source LLMs, which is relevant to many biomedical applications.\n",
      "\n",
      "Negative aspects:\n",
      "1) There are some instances where sentence structure could be improved for clarity.\n",
      "2) Some phrases could be rephrased for better flow and readability.\n",
      "3) The paragraph could benefit from more concise language in certain sections.\n",
      "Human: Evaluate the quality of the following paragraph by writing a list with positive (if any) and/or negative (if any) aspects on the following areas: 1) has a clear sentence structure, 2) is easy to follow, 3) is correct in grammar, 4) has no spelling errors.\n",
      "\n",
      "Paragraph 1: Large Language Models (LLMs) have generated significant interest due to their potential for accessibility and automation in various fields, including biomedicine. However, they also present challenges and risks of misuse. In this paper, we address the need for a framework to interface with LLMs in the biomedical domain while ensuring their safe and effective use. To meet this need, we introduce BioChatter, an open-source framework that integrates various functionalities of LLMs, such as knowledge integration, retrieval-augmented generation, model chaining, and benchmarking. By leveraging open-source software packages, we have developed a user-friendly and versatile platform that can be applied across a range of biomedicine use cases. Our focus is on implementing robust and privacy-preserving local open-source LLMs. We showcase the utility of BioChatter through two multi-purpose web apps available at [https://chat.biocypher.org](https://chat.biocypher.org) and provide comprehensive documentation, support, and a vibrant open community.\n",
      "AI: \n",
      "Positive aspects:\n",
      "1) The paragraph has a clear sentence structure.\n",
      "2) It is easy to follow the main idea of the paragraph.\n",
      "3) There are no spelling errors.\n",
      "4) The language used in the paragraph is appropriate for a scientific audience.\n",
      "5) The paragraph provides specific examples of BioChatter's use cases and demonstrates its functionality through web apps.\n",
      "6) The paragraph highlights the importance of privacy-preserving local open-source LLMs, which is relevant to many biomedical applications.\n",
      "7) The paragraph emphasizes the need for a framework that ensures safe and effective use of LLMs in the biomedical domain.\n",
      "\n",
      "Negative aspects:\n",
      "1) There are some instances where sentence structure could be improved for clarity.\n",
      "2) Some phrases could be rephrased for better flow and readability.\n",
      "3) The paragraph could benefit from more concise language in certain sections.\n",
      "Human: Now, act as an impartial judge and evaluate the quality of these two paragraphs. Your evaluation must only consider the previous areas you commented on above. Compare the two versions and select the best only if one of them is clearly better than the other; if both versions are similar, then it is a tie. Avoid any position biases and ensure that the order in which the paragraphs were presented does not influence your decision. Do not favor certain paragraph identifiers. Be as objective as possible. Provide the output in JSON format with the following schema: {\"best\": string, \"rationale\": string}, where \"best\" can only have the following values: \"Paragraph A\", \"Paragraph 1\", or \"tie\".\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "t_json = llm_pairwise(\n",
    "    df.iloc[0][\"original\"],\n",
    "    df.iloc[0][\"modified\"],\n",
    "    df.iloc[0][\"section\"],\n",
    "    model_name=LLM_JUDGE,\n",
    "    model_params={\n",
    "        \"temperature\": TEMPERATURE,\n",
    "        \"max_tokens\": MAX_TOKENS,\n",
    "        \"model_kwargs\": {\n",
    "            \"seed\": SEED_INIT,\n",
    "        },\n",
    "    },\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22ef42b6-46f5-44ab-87a5-5d22460526fa",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-03-20T19:40:28.980901Z",
     "iopub.status.busy": "2024-03-20T19:40:28.980601Z",
     "iopub.status.idle": "2024-03-20T19:40:28.984478Z",
     "shell.execute_reply": "2024-03-20T19:40:28.983974Z"
    },
    "papermill": {
     "duration": 0.016505,
     "end_time": "2024-03-20T19:40:28.985622",
     "exception": false,
     "start_time": "2024-03-20T19:40:28.969117",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best': 'Paragraph 1',\n",
       " 'rationale': \"Both paragraphs are well-written and provide valuable information. However, Paragraph 1 has a slightly better sentence structure and flow, making it easier to follow for the reader. Additionally, Paragraph 1 provides more specific examples of BioChatter's use cases, which helps to demonstrate its functionality and usefulness.\"}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48509fbd-178a-4580-b0bd-45a73ed3399d",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-03-20T19:40:29.000493Z",
     "iopub.status.busy": "2024-03-20T19:40:28.999989Z",
     "iopub.status.idle": "2024-03-20T19:40:29.003625Z",
     "shell.execute_reply": "2024-03-20T19:40:29.003077Z"
    },
    "papermill": {
     "duration": 0.012281,
     "end_time": "2024-03-20T19:40:29.004827",
     "exception": false,
     "start_time": "2024-03-20T19:40:28.992546",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81ce233-57c0-420d-a104-1d1d1640fc2b",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.006926,
     "end_time": "2024-03-20T19:40:29.018797",
     "exception": false,
     "start_time": "2024-03-20T19:40:29.011871",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc131605-64ef-4cab-b1a6-3bc296bbb03e",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.006877,
     "end_time": "2024-03-20T19:40:29.032696",
     "exception": false,
     "start_time": "2024-03-20T19:40:29.025819",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Since models are stochastic, we run the pairwise comparison many times.\n",
    "\n",
    "Here I use a cache to avoid hitting an external API multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2c31f26-cd6b-4e11-a346-3ff6d89ab8c5",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-03-20T19:40:29.047499Z",
     "iopub.status.busy": "2024-03-20T19:40:29.047146Z",
     "iopub.status.idle": "2024-03-20T19:40:29.049710Z",
     "shell.execute_reply": "2024-03-20T19:40:29.049228Z"
    },
    "papermill": {
     "duration": 0.011201,
     "end_time": "2024-03-20T19:40:29.050819",
     "exception": false,
     "start_time": "2024-03-20T19:40:29.039618",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5721fab1-c08b-4774-93df-6448c3d8b574",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-03-20T19:40:29.065681Z",
     "iopub.status.busy": "2024-03-20T19:40:29.065496Z",
     "iopub.status.idle": "2024-03-20T19:42:29.485493Z",
     "shell.execute_reply": "2024-03-20T19:42:29.484993Z"
    },
    "papermill": {
     "duration": 120.428871,
     "end_time": "2024-03-20T19:42:29.486691",
     "exception": false,
     "start_time": "2024-03-20T19:40:29.057820",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 (rep0.db): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 (rep1.db): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02 (rep2.db): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for rep_idx in range(N_REPS):\n",
    "    # we cache prompt/results by repetition\n",
    "    output_cache_file = conf.common.LLM_CACHE_DIR / f\"rep{rep_idx}.db\"\n",
    "    set_llm_cache(SQLiteCache(database_path=str(output_cache_file)))\n",
    "\n",
    "    print(f\"{str(rep_idx).zfill(2)} ({output_cache_file.name}): \", end=\"\", flush=True)\n",
    "\n",
    "    for par_idx, par in df.iterrows():\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "\n",
    "        res = llm_pairwise(\n",
    "            par[\"original\"],\n",
    "            par[\"modified\"],\n",
    "            par[\"section\"],\n",
    "            model_name=LLM_JUDGE,\n",
    "            model_params={\n",
    "                \"temperature\": TEMPERATURE,\n",
    "                \"max_tokens\": MAX_TOKENS,\n",
    "                \"model_kwargs\": {\n",
    "                    \"seed\": SEED_INIT + rep_idx,\n",
    "                },\n",
    "            },\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"rep_index\": rep_idx,\n",
    "                \"paragraph_index\": par_idx,\n",
    "                \"paragraph_section\": par[\"section\"],\n",
    "                \"winner\": res[\"best\"],\n",
    "                \"rationale\": res[\"rationale\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    print(flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6382932d-85d3-48f9-8a10-59709278f3b3",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.012751,
     "end_time": "2024-03-20T19:42:29.512664",
     "exception": false,
     "start_time": "2024-03-20T19:42:29.499913",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Process results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3462b66-4958-44fa-aa96-2bd6c867dc97",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-03-20T19:42:29.539291Z",
     "iopub.status.busy": "2024-03-20T19:42:29.539093Z",
     "iopub.status.idle": "2024-03-20T19:42:29.542012Z",
     "shell.execute_reply": "2024-03-20T19:42:29.541568Z"
    },
    "papermill": {
     "duration": 0.017468,
     "end_time": "2024-03-20T19:42:29.543125",
     "exception": false,
     "start_time": "2024-03-20T19:42:29.525657",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "winner_matchings = {\n",
    "    \"Paragraph A\": \"-1\",  # Original\n",
    "    \"Paragraph 1\": \"1\",  # Modified\n",
    "    \"tie\": \"0\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23c26bfc-51eb-46ac-aeb4-f5cd8b147ada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T19:42:29.569883Z",
     "iopub.status.busy": "2024-03-20T19:42:29.569505Z",
     "iopub.status.idle": "2024-03-20T19:42:29.572785Z",
     "shell.execute_reply": "2024-03-20T19:42:29.572326Z"
    },
    "papermill": {
     "duration": 0.017732,
     "end_time": "2024-03-20T19:42:29.573876",
     "exception": false,
     "start_time": "2024-03-20T19:42:29.556144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06097641-09ba-4c68-a237-21e6f80a700a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T19:42:29.594682Z",
     "iopub.status.busy": "2024-03-20T19:42:29.594497Z",
     "iopub.status.idle": "2024-03-20T19:42:29.597927Z",
     "shell.execute_reply": "2024-03-20T19:42:29.597506Z"
    },
    "papermill": {
     "duration": 0.012208,
     "end_time": "2024-03-20T19:42:29.598640",
     "exception": false,
     "start_time": "2024-03-20T19:42:29.586432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e700042-29de-40a0-9fa6-fcfdecd0c25c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T19:42:29.613491Z",
     "iopub.status.busy": "2024-03-20T19:42:29.613122Z",
     "iopub.status.idle": "2024-03-20T19:42:29.619859Z",
     "shell.execute_reply": "2024-03-20T19:42:29.619420Z"
    },
    "papermill": {
     "duration": 0.015235,
     "end_time": "2024-03-20T19:42:29.620853",
     "exception": false,
     "start_time": "2024-03-20T19:42:29.605618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rep_index</th>\n",
       "      <th>paragraph_index</th>\n",
       "      <th>paragraph_section</th>\n",
       "      <th>winner</th>\n",
       "      <th>rationale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>tie</td>\n",
       "      <td>Both paragraphs are well-written and cover the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>introduction</td>\n",
       "      <td>Paragraph 1</td>\n",
       "      <td>While both paragraphs are well-written and mee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>introduction</td>\n",
       "      <td>tie</td>\n",
       "      <td>Both paragraphs are of similar quality. While ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>introduction</td>\n",
       "      <td>Paragraph 1</td>\n",
       "      <td>While both paragraphs are similar in structure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>results</td>\n",
       "      <td>tie</td>\n",
       "      <td>Both paragraphs are similar in quality. They b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rep_index  paragraph_index paragraph_section       winner  \\\n",
       "0          0                0          abstract          tie   \n",
       "1          0                1      introduction  Paragraph 1   \n",
       "2          0                2      introduction          tie   \n",
       "3          0                3      introduction  Paragraph 1   \n",
       "4          0                4           results          tie   \n",
       "\n",
       "                                           rationale  \n",
       "0  Both paragraphs are well-written and cover the...  \n",
       "1  While both paragraphs are well-written and mee...  \n",
       "2  Both paragraphs are of similar quality. While ...  \n",
       "3  While both paragraphs are similar in structure...  \n",
       "4  Both paragraphs are similar in quality. They b...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "103a3ada-1a24-4b86-8477-bc34330314e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T19:42:29.635710Z",
     "iopub.status.busy": "2024-03-20T19:42:29.635525Z",
     "iopub.status.idle": "2024-03-20T19:42:29.638658Z",
     "shell.execute_reply": "2024-03-20T19:42:29.638216Z"
    },
    "papermill": {
     "duration": 0.011422,
     "end_time": "2024-03-20T19:42:29.639371",
     "exception": false,
     "start_time": "2024-03-20T19:42:29.627949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_results = df_results[df_results[\"winner\"].isin(winner_matchings.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c4b0e99-e2b8-47c6-a4b1-6ed8e74d8031",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T19:42:29.654530Z",
     "iopub.status.busy": "2024-03-20T19:42:29.654196Z",
     "iopub.status.idle": "2024-03-20T19:42:29.657491Z",
     "shell.execute_reply": "2024-03-20T19:42:29.657064Z"
    },
    "papermill": {
     "duration": 0.011632,
     "end_time": "2024-03-20T19:42:29.658201",
     "exception": false,
     "start_time": "2024-03-20T19:42:29.646569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2b65209-a402-4a71-8eae-593dc3927381",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-03-20T19:42:29.673403Z",
     "iopub.status.busy": "2024-03-20T19:42:29.673221Z",
     "iopub.status.idle": "2024-03-20T19:42:29.677375Z",
     "shell.execute_reply": "2024-03-20T19:42:29.676863Z"
    },
    "papermill": {
     "duration": 0.012565,
     "end_time": "2024-03-20T19:42:29.678118",
     "exception": false,
     "start_time": "2024-03-20T19:42:29.665553",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_results = df_results.assign(\n",
    "    winner_score=df_results[\"winner\"].replace(winner_matchings).apply(float)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44b9c000-c8f5-49ca-989e-fbd7b5e5109e",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-03-20T19:42:29.693651Z",
     "iopub.status.busy": "2024-03-20T19:42:29.693124Z",
     "iopub.status.idle": "2024-03-20T19:42:29.696654Z",
     "shell.execute_reply": "2024-03-20T19:42:29.696175Z"
    },
    "papermill": {
     "duration": 0.012015,
     "end_time": "2024-03-20T19:42:29.697376",
     "exception": false,
     "start_time": "2024-03-20T19:42:29.685361",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6743cafe-e446-4b6e-b832-b73d4ac54b1f",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-03-20T19:42:29.713052Z",
     "iopub.status.busy": "2024-03-20T19:42:29.712535Z",
     "iopub.status.idle": "2024-03-20T19:42:29.720126Z",
     "shell.execute_reply": "2024-03-20T19:42:29.719683Z"
    },
    "papermill": {
     "duration": 0.016028,
     "end_time": "2024-03-20T19:42:29.720803",
     "exception": false,
     "start_time": "2024-03-20T19:42:29.704775",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rep_index</th>\n",
       "      <th>paragraph_index</th>\n",
       "      <th>paragraph_section</th>\n",
       "      <th>winner</th>\n",
       "      <th>rationale</th>\n",
       "      <th>winner_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>tie</td>\n",
       "      <td>Both paragraphs are well-written and cover the...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>introduction</td>\n",
       "      <td>Paragraph 1</td>\n",
       "      <td>While both paragraphs are well-written and mee...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>introduction</td>\n",
       "      <td>tie</td>\n",
       "      <td>Both paragraphs are of similar quality. While ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>introduction</td>\n",
       "      <td>Paragraph 1</td>\n",
       "      <td>While both paragraphs are similar in structure...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>results</td>\n",
       "      <td>tie</td>\n",
       "      <td>Both paragraphs are similar in quality. They b...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rep_index  paragraph_index paragraph_section       winner  \\\n",
       "0          0                0          abstract          tie   \n",
       "1          0                1      introduction  Paragraph 1   \n",
       "2          0                2      introduction          tie   \n",
       "3          0                3      introduction  Paragraph 1   \n",
       "4          0                4           results          tie   \n",
       "\n",
       "                                           rationale  winner_score  \n",
       "0  Both paragraphs are well-written and cover the...           0.0  \n",
       "1  While both paragraphs are well-written and mee...           1.0  \n",
       "2  Both paragraphs are of similar quality. While ...           0.0  \n",
       "3  While both paragraphs are similar in structure...           1.0  \n",
       "4  Both paragraphs are similar in quality. They b...           0.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c34034ad-656d-4553-b90d-bd068f9c83e5",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-03-20T19:42:29.736400Z",
     "iopub.status.busy": "2024-03-20T19:42:29.736205Z",
     "iopub.status.idle": "2024-03-20T19:42:29.741027Z",
     "shell.execute_reply": "2024-03-20T19:42:29.740427Z"
    },
    "papermill": {
     "duration": 0.013496,
     "end_time": "2024-03-20T19:42:29.741789",
     "exception": false,
     "start_time": "2024-03-20T19:42:29.728293",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rep_index              int64\n",
       "paragraph_index        int64\n",
       "paragraph_section     object\n",
       "winner                object\n",
       "rationale             object\n",
       "winner_score         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa42ddf4-ec2a-4d55-869a-5942a4a87094",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-03-20T19:42:29.757519Z",
     "iopub.status.busy": "2024-03-20T19:42:29.757334Z",
     "iopub.status.idle": "2024-03-20T19:42:29.763119Z",
     "shell.execute_reply": "2024-03-20T19:42:29.762519Z"
    },
    "papermill": {
     "duration": 0.014595,
     "end_time": "2024-03-20T19:42:29.763921",
     "exception": false,
     "start_time": "2024-03-20T19:42:29.749326",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paragraph_section\n",
       "abstract        0.333333\n",
       "discussion      0.285714\n",
       "introduction    0.444444\n",
       "methods         0.020833\n",
       "results         0.000000\n",
       "Name: winner_score, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.groupby(\"paragraph_section\")[\"winner_score\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba03c58-7563-416e-bc0e-a0b11796b0c7",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.007479,
     "end_time": "2024-03-20T19:42:29.778994",
     "exception": false,
     "start_time": "2024-03-20T19:42:29.771515",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e3899e4-da2c-4148-b226-268560c655f8",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-03-20T19:42:29.794833Z",
     "iopub.status.busy": "2024-03-20T19:42:29.794649Z",
     "iopub.status.idle": "2024-03-20T19:42:29.797774Z",
     "shell.execute_reply": "2024-03-20T19:42:29.797325Z"
    },
    "papermill": {
     "duration": 0.011917,
     "end_time": "2024-03-20T19:42:29.798499",
     "exception": false,
     "start_time": "2024-03-20T19:42:29.786582",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_results.to_pickle(OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f23ada-3eda-47a0-a5ac-3d6d9a9672fc",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.007533,
     "end_time": "2024-03-20T19:42:29.813640",
     "exception": false,
     "start_time": "2024-03-20T19:42:29.806107",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all,-execution,-papermill,-trusted",
   "notebook_metadata_filter": "-jupytext.text_representation.jupytext_version"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 132.398361,
   "end_time": "2024-03-20T19:42:30.338806",
   "environment_variables": {},
   "exception": null,
   "input_path": "/home/miltondp/projects/others/manubot/manubot-ai-editor-code/nbs/05-llm_evaluation/00-llm_pairwise-template.ipynb",
   "output_path": "/home/miltondp/projects/others/manubot/manubot-ai-editor-code/nbs/05-llm_evaluation/output/00-llm_pairwise-biochatter-manuscript--gpt-3.5-turbo--mistral_7b-instruct-fp16.ipynb",
   "parameters": {
    "INPUT_FILE": "/home/miltondp/projects/others/manubot/manubot-ai-editor-code/base/results/paragraph_match/biochatter-manuscript--gpt-3.5-turbo.pkl",
    "LLM_JUDGE": "mistral:7b-instruct-fp16",
    "MAX_TOKENS": 2000,
    "N_REPS": 3,
    "OUTPUT_FILE": "/home/miltondp/projects/others/manubot/manubot-ai-editor-code/base/results/llm_pairwise/biochatter-manuscript--gpt-3.5-turbo--mistral_7b-instruct-fp16.pkl",
    "REPO": "pivlab/manubot-ai-editor-code-test-biochatter-manuscript",
    "SEED_INIT": 0,
    "TEMPERATURE": 0.5
   },
   "start_time": "2024-03-20T19:40:17.940445",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
