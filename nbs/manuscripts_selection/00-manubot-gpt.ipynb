{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "070a050a-44d1-42c2-b274-c8c180a2a0ba",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.002602,
     "end_time": "2024-03-15T00:15:15.975569",
     "exception": false,
     "start_time": "2024-03-15T00:15:15.972967",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a57f5-0e78-4d65-82c4-c81bdb9a02e4",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.001866,
     "end_time": "2024-03-15T00:15:15.987917",
     "exception": false,
     "start_time": "2024-03-15T00:15:15.986051",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This notebook tests the PyGithub package to read a GitHub repository containing a Manubot-based manuscript."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b237f234-dc98-43e9-8ff5-8922c410c377",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.00186,
     "end_time": "2024-03-15T00:15:15.991817",
     "exception": false,
     "start_time": "2024-03-15T00:15:15.989957",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70413318-1f5e-4d58-b1a2-cb4f01c13e86",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.113882,
     "end_time": "2024-03-15T00:15:16.107842",
     "exception": false,
     "start_time": "2024-03-15T00:15:15.993960",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from github import Github, Auth\n",
    "\n",
    "from proj import conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f78fd18-86b7-40b9-b80e-a8b18d001682",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.010426,
     "end_time": "2024-03-15T00:15:16.119934",
     "exception": false,
     "start_time": "2024-03-15T00:15:16.109508",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Settings/paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a3ceca-1480-45b0-b04d-cb402ff95abf",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.000955,
     "end_time": "2024-03-15T00:15:16.122000",
     "exception": false,
     "start_time": "2024-03-15T00:15:16.121045",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "REPO = \"pivlab/manubot-ai-editor-code-test-manubot-gpt-manuscript\"\n",
    "# PR 1: gpt-3.5-turbo\n",
    "# PR 2: gpt-4-0125-preview\n",
    "PR = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42b83b5-84b7-45ff-88ee-3651aa5c9c55",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.000952,
     "end_time": "2024-03-15T00:15:16.124013",
     "exception": false,
     "start_time": "2024-03-15T00:15:16.123061",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Get Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1d1f476-f5b5-4d1c-9c3a-822e9bef4b27",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.004874,
     "end_time": "2024-03-15T00:15:16.129892",
     "exception": false,
     "start_time": "2024-03-15T00:15:16.125018",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "auth = Auth.Token(conf.github.API_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e3db6e2-f267-4d60-8ff3-703698a09f88",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.006454,
     "end_time": "2024-03-15T00:15:16.137412",
     "exception": false,
     "start_time": "2024-03-15T00:15:16.130958",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = Github(auth=auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc6a365d-59f5-4537-9fd7-869ee4156046",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.001072,
     "end_time": "2024-03-15T00:15:16.140268",
     "exception": false,
     "start_time": "2024-03-15T00:15:16.139196",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo = g.get_repo(REPO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d9fb5d-6838-484b-9202-ceac74fcb336",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Get Pull Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "297c9dec-9e00-490d-8723-44208b3fe8f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pr = repo.get_pull(PR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "064b1017-a495-48b3-bea3-1b9a67ad1b6f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File(sha=\"a9ee44b5bd2d27ec24210ff7cd8f306dc982fa6b\", filename=\"content/01.abstract.md\"),\n",
       " File(sha=\"ed907c4f5b6cc27f9cc1571ab3c63de21f33e711\", filename=\"content/02.introduction.md\"),\n",
       " File(sha=\"11c4cd176e7af7b4cc7a8f6b3d3adbac5def2993\", filename=\"content/03.methods.md\"),\n",
       " File(sha=\"4219b5e148a60c79bcdf3a56b9ca730a5ef697dd\", filename=\"content/04.results.md\"),\n",
       " File(sha=\"d25ad453ee1ee0c3dacd6a4b2defa08d51baf649\", filename=\"content/05.conclusions.md\")]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pr.get_files())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bc9b271-7ed2-4994-9d36-c8afa946b017",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pr_commits = list(pr.get_commits())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "446a1453-5729-4687-9b93-8165dd0e2793",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Commit(sha=\"abe9b961d21b2f1e160a05c634231fbdba687982\")]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_commits[0].parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c2382a1-adcc-47dc-8c75-d34f8500f93e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abe9b961d21b2f1e160a05c634231fbdba687982\n"
     ]
    }
   ],
   "source": [
    "pr_prev = pr_commits[0].parents[0].sha\n",
    "print(pr_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96c9b088-a166-49d6-a0df-64d2cf690b7e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "803503044ab141e03a2f9b1f3bbb4bec9a00fb4d\n"
     ]
    }
   ],
   "source": [
    "pr_curr = pr_commits[0].sha\n",
    "print(pr_curr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10872c1e-0184-46c6-a04f-dce43438d404",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Get file list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "242729cf-1778-4162-b813-249ae6c8b632",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File(sha=\"a9ee44b5bd2d27ec24210ff7cd8f306dc982fa6b\", filename=\"content/01.abstract.md\"),\n",
       " File(sha=\"ed907c4f5b6cc27f9cc1571ab3c63de21f33e711\", filename=\"content/02.introduction.md\"),\n",
       " File(sha=\"11c4cd176e7af7b4cc7a8f6b3d3adbac5def2993\", filename=\"content/03.methods.md\"),\n",
       " File(sha=\"4219b5e148a60c79bcdf3a56b9ca730a5ef697dd\", filename=\"content/04.results.md\"),\n",
       " File(sha=\"d25ad453ee1ee0c3dacd6a4b2defa08d51baf649\", filename=\"content/05.conclusions.md\")]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr_files = [f for f in pr.get_files() if f.filename.endswith(\".md\")]\n",
    "display(pr_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce10792-ba0d-4716-9dcd-b44c2eb668d4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Get file content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1558f08b-19a8-4951-8dea-228d7f59099d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'content/03.methods.md'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr_filename = pr_files[2].filename\n",
    "display(pr_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e34ec8c-9420-4988-8005-2ced76e5e0f0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Implementing AI-based revision into the Manubot publishing ecosystem\n",
      "\n",
      "We propose a human-centric approach for the use of AI in manuscript writing, which consists of the following steps:\n",
      "1) human authors write the manuscript content;\n",
      "2) an LLM revises the manuscript, generating a set of suggested changes;\n",
      "3) human authors review the suggested changes, and the approved edits are then integrated into the manuscript.\n",
      "By focusing on human review, this approach attempts to mitigate the risk of generating incorrect or misleading information.\n",
      "To implement this human-centric approach, we developed a tool called the Manubot AI Editor, which is part of the Manubot infrastructure for scholarly publishing [@doi:10.1371/journal.pcbi.1007128].\n",
      "\n",
      "### Overview of the Manubot AI Editor\n",
      "\n",
      "![\n",
      "**AI-based revision applied on a Manubot-based manuscript.**\n",
      "**a)** A manuscript (written with Manubot) with different sections.\n",
      "**b)** The prompt generator integrates metadata using prompt templates to generate section-specific prompts for each paragraph.\n",
      "If a paragraph belongs to a non-standard section, then a default prompt will be used to perform a basic revision only.\n",
      "The prompt for the Methods section includes the formatting of equations with identifiers.\n",
      "All sections' prompts include these instructions: *\"the text grammar is correct, spelling errors are fixed, and the text has a clear sentence structure\"*, although these are only shown for abstracts.\n",
      "Our tool allows the user to provide a custom prompt instead of using the default ones shown here.\n",
      "](images/figure_1.svg \"AI-based revision applied on a Manubot manuscript\"){#fig:ai_revision width=\"75%\"}\n",
      "\n",
      "The Manubot AI Editor is an AI-based revision infrastructure built into Manubot [@doi:10.1371/journal.pcbi.1007128], a tool for collaborative writing of scientific manuscripts.\n",
      "Manubot integrates with popular version control platforms such as GitHub, allowing authors to easily track changes and collaborate on writing in real time.\n",
      "Furthermore, Manubot automates the process of generating a formatted manuscript (e.g., HTML, PDF, DOCX; Figure {@fig:ai_revision}a shows the HTML output).\n",
      "Built on this modern and open paradigm, our Manubot AI Editor ([https://github.com/manubot/manubot-ai-editor](https://github.com/manubot/manubot-ai-editor)) includes three components:\n",
      "1) a Python library that provides classes and functions to read the manuscript content and its metadata, calls the LLM for automatic text revision, and writes the results back;\n",
      "2) a GitHub Actions workflow that uses our Python library within GitHub to preserve provenance information for transparency;\n",
      "3) a prompt generator that integrates the manuscript's metadata using prompt templates to generate section-specific prompts for each paragraph (Figure {@fig:ai_revision}b).\n",
      "\n",
      "\n",
      "The GitHub Actions workflow allows users to easily trigger an automated revision task on the entire manuscript or specific sections of it.\n",
      "When the action is triggered, the manuscript is parsed by section and then by paragraph (Figure {@fig:ai_revision}b), which are passed to the language model along with a set of custom prompts.\n",
      "The model then returns a revised version of the text.\n",
      "Our workflow uses the GitHub API to generate a new pull request, allowing the user to review and modify the output before merging the changes into the manuscript.\n",
      "This workflow attributes text to either the human user or the AI language model, which may be important in light of potential future legal decisions that could alter the copyright landscape around the outputs of generative models.\n",
      "\n",
      "\n",
      "We used the [OpenAI API](https://openai.com/api/) for access to these models.\n",
      "Since this API incurs a cost with each run that depends on manuscript length, we implemented a workflow in GitHub Actions that can be manually triggered by the user.\n",
      "Our implementation allows users to tune the costs to their needs by enabling them to select specific sections for revision instead of the entire manuscript.\n",
      "Additionally, several model parameters can be adjusted to further tune costs, such as the language model version (including Davinci and Curie, the current GPT-3.5 Turbo and GPT-4, and potentially newly published ones), how much risk the model will take, or the \"quality\" of the completions.\n",
      "For instance, using Davinci models, the cost per run is under $0.50 for most manuscripts.\n",
      "\n",
      "\n",
      "### Implementation details\n",
      "\n",
      "To run the workflow, the user must specify the branch that will be revised, select the files/sections of the manuscript (optional), specify the language model to use (`text-davinci-003` by default), an optional custom prompt (section-specific prompts are used by default), and provide the output branch name.\n",
      "For more advanced users, it is also possible to change most of the tool's behavior or the language model parameters.\n",
      "\n",
      "\n",
      "When the workflow is triggered, it downloads the manuscript by cloning the specified branch.\n",
      "It revises all of the manuscript files, or only some of them if the user specifies a subset.\n",
      "Next, each paragraph in the file is read and submitted to the OpenAI API for revision.\n",
      "If the request is successful, the tool will write the revised paragraph in place of the original one, using one sentence per line (which is the recommended format for the input text).\n",
      "If the request fails, the tool might try again (up to five times by default) if it is a common error (such as \"server overloaded\") or a model-specific error that requires changing some of its parameters.\n",
      "If the error cannot be handled or the maximum number of retries is reached, the original paragraph is written instead with an HTML comment at the top explaining the cause of the error.\n",
      "This allows the user to debug the problem and attempt to fix it if desired.\n",
      "\n",
      "\n",
      "As shown in Figure {@fig:ai_revision}b, each API request comprises a prompt (the instructions given to the model) and the paragraph to be revised.\n",
      "Unless the user specifies a custom prompt, the tool will use a section-specific prompt generator that incorporates the manuscript title and keywords.\n",
      "Therefore, both must be accurate to obtain the best revision outcomes.\n",
      "The other key component to process a paragraph is its section.\n",
      "For instance, the abstract is a set of sentences with no citations, whereas a paragraph from the Introduction section has several references to other scientific papers.\n",
      "A paragraph in the Results section has fewer citations but many references to figures or tables, and must provide enough details about the experiments to understand and interpret the outcomes.\n",
      "The Methods section is more dependent on the type of paper, but in general, it has to provide technical details and sometimes mathematical formulas and equations.\n",
      "Therefore, we designed section-specific prompts, which we found led to the most useful suggestions.\n",
      "Figure and table captions, as well as paragraphs that contain only one or two sentences and fewer than sixty words, are not processed and are copied directly to the output file.\n",
      "\n",
      "\n",
      "The section of a paragraph is automatically inferred from the file name using a simple strategy, such as if \"introduction\" or \"methods\" is part of the file name.\n",
      "If the tool fails to infer a section from the file, the user can still specify to which section the file belongs.\n",
      "The section can be a standard one (abstract, introduction, results, methods, or discussion) for which a specific prompt is used (Figure {@fig:ai_revision}b), or a non-standard one for which a default prompt is used to instruct the model to perform basic revision.\n",
      "This includes *\"minimizing the use of jargon, ensuring text grammar is correct, fixing spelling errors, and making sure the text has a clear sentence structure.\"*\n",
      "\n",
      "\n",
      "### Properties of language models\n",
      "\n",
      "The Manubot AI Editor uses the [Chat Completions API](https://platform.openai.com/docs/guides/text-generation/chat-completions-api) to process each paragraph.\n",
      "We have tested our tool using both the Davinci and Curie models, including `text-davinci-003`, `text-davinci-edit-001`, and `text-curie-001`.\n",
      "Within the GPT-3 family, the Davinci models are the most powerful, while the Curie models are less capable but faster and less expensive.\n",
      "<!-- We mainly focused on the completion endpoint, as the edits endpoint was currently in beta. -->\n",
      "All models can be fine-tuned using different parameters (refer to [OpenAI - API Reference](https://platform.openai.com/docs/api-reference/chat/create)), and the most important ones can be easily adjusted using our tool.\n",
      "\n",
      "\n",
      "Language models for text completion have a context length that indicates the limit of tokens they can process (tokens are common character sequences in text).\n",
      "This limit includes the size of the prompt and the paragraph, as well as the maximum number of tokens to generate for the completion (parameter `max_tokens`).\n",
      "For instance, the context length of Davinci models is 4,000 and for Curie, it is 2,048 (see [OpenAI - Models overview](https://platform.openai.com/docs/models/gpt-3)).\n",
      "<!-- Therefore, it is not possible to use the entire manuscript as input, not even entire sections. -->\n",
      "To ensure we never exceed this context length, our AI-assisted revision software processes each paragraph of the manuscript with section-specific prompts, as shown in Figure {@fig:ai_revision}b.\n",
      "This approach allows us to process large manuscripts by breaking them into smaller chunks of text.\n",
      "However, since the language model only processes a single paragraph from a section, it can potentially lose important context needed to produce a better output.\n",
      "Nonetheless, we find that the model still produces high-quality revisions (see [Results](#sec:results)).\n",
      "Additionally, the maximum number of tokens (parameter `max_tokens`) is set as twice the estimated number of tokens in the paragraph (one token approximately represents four characters, see [OpenAI - Tokenizer](https://platform.openai.com/tokenizer)).\n",
      "The tool automatically adjusts this parameter and performs the request again if a related error is returned by the API.\n",
      "The user can also force the tool to either use a fixed value for `max_tokens` for all paragraphs, or change the fraction of maximum tokens based on the estimated paragraph size (two by default).\n",
      "\n",
      "\n",
      "The language models used are stochastic, meaning they generate a different revision for the same input paragraph each time.\n",
      "This behavior can be adjusted by using the \"sampling temperature\" or \"nucleus sampling\" parameters (we use `temperature=0.5` by default).\n",
      "Although we selected default values that work well across multiple manuscripts, these parameters can be changed to make the model more deterministic.\n",
      "The user can also instruct the model to generate several completions and select the one with the highest log probability per token, which can improve the quality of the revision.\n",
      "Our implementation generates only one completion (parameter `best_of=1`) to avoid potentially high costs for the user.\n",
      "Additionally, our workflow allows the user to process either the entire manuscript or individual sections.\n",
      "This provides more cost-effective control while focusing on a single piece of text, wherein the user can run the tool several times and pick the preferred revised text.\n",
      "\n",
      "\n",
      "### Installation and use\n",
      "\n",
      "The Manubot AI Editor is part of the standard Manubot template manuscript, referred to as rootstock, and is available at [https://github.com/manubot/rootstock](https://github.com/manubot/rootstock).\n",
      "Users wishing to use the workflow only need to follow the standard procedures to install Manubot.\n",
      "The section \"AI-assisted authoring\", found in the file `USAGE.md` of the rootstock repository, explains how to enable the tool.\n",
      "Afterward, the workflow (named `ai-revision`) will be available and ready to use under the Actions tab of the user's manuscript repository.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(repo.get_contents(pr_filename, pr_prev).decoded_content.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db1bf394-3824-4cd3-a80f-9037f9a8c5b0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Implementing AI-based revision into the Manubot publishing ecosystem\n",
      "\n",
      "We propose a human-centric methodology for integrating Artificial Intelligence (AI) into the process of academic manuscript writing.\n",
      "This methodology is structured around a collaborative framework between human authors and AI, specifically large language models (LLMs).\n",
      "The process unfolds in several distinct steps: \n",
      "\n",
      "1) Human authors initially draft the manuscript content, establishing the foundational narrative and scientific arguments.\n",
      "2) Subsequently, an LLM reviews this initial manuscript draft, generating a comprehensive set of suggested revisions.\n",
      "These suggestions can range from grammatical corrections to more substantive content recommendations.\n",
      "3) Human authors then meticulously review these suggested changes.\n",
      "Only the edits that are deemed appropriate and accurate by the authors are integrated into the manuscript.\n",
      "\n",
      "This approach is designed to leverage the strengths of both human expertise and AI capabilities, with a particular emphasis on human oversight to prevent the introduction of inaccuracies or misleading information into the academic discourse.\n",
      "To operationalize this human-centric approach, we developed a specialized tool known as the Manubot AI Editor.\n",
      "This tool is a novel component of the Manubot framework, which is specifically designed to support scholarly publishing.\n",
      "The Manubot infrastructure facilitates a seamless integration of AI-assisted authoring within the broader context of academic writing and publishing [@doi:10.1371/journal.pcbi.1007128].\n",
      "\n",
      "### Overview of the Manubot AI Editor\n",
      "\n",
      "![\n",
      "**AI-based revision applied on a Manubot-based manuscript.**\n",
      "**a)** A manuscript (written with Manubot) with different sections.\n",
      "**b)** The prompt generator integrates metadata using prompt templates to generate section-specific prompts for each paragraph.\n",
      "If a paragraph belongs to a non-standard section, then a default prompt will be used to perform a basic revision only.\n",
      "The prompt for the Methods section includes the formatting of equations with identifiers.\n",
      "All sections' prompts include these instructions: *\"the text grammar is correct, spelling errors are fixed, and the text has a clear sentence structure\"*, although these are only shown for abstracts.\n",
      "Our tool allows the user to provide a custom prompt instead of using the default ones shown here.\n",
      "](images/figure_1.svg \"AI-based revision applied on a Manubot manuscript\"){#fig:ai_revision width=\"75%\"}\n",
      "\n",
      "The Manubot AI Editor represents a pioneering infrastructure for AI-assisted revision, built atop the Manubot platform, which is renowned for facilitating the collaborative writing of scientific manuscripts through integration with version control systems like GitHub [@doi:10.1371/journal.pcbi.1007128].\n",
      "This integration not only simplifies the tracking of modifications and collaboration in real-time but also streamlines the production of formatted manuscripts in various formats such as HTML, PDF, and DOCX.\n",
      "An illustration of the HTML formatted output is provided in Figure {@fig:ai_revision}a.\n",
      "Leveraging the principles of openness and modernity, the Manubot AI Editor, accessible at [https://github.com/manubot/manubot-ai-editor](https://github.com/manubot/manubot-ai-editor), is composed of three main components: \n",
      "\n",
      "1) A Python library, offering a suite of classes and functions for reading the manuscript's content and metadata, invoking Large Language Models (LLMs) for text revision, and subsequently recording the outcomes.\n",
      "2) A GitHub Actions workflow, which employs the aforementioned Python library within GitHub's ecosystem to maintain a transparent record of the provenance information.\n",
      "3) A prompt generator that utilizes the manuscript's metadata in conjunction with predefined templates to craft section-specific prompts for each paragraph, as depicted in Figure {@fig:ai_revision}b.\n",
      "\n",
      "This comprehensive approach ensures that the Manubot AI Editor not only enhances the efficiency and quality of academic writing but also upholds the principles of transparency and collaboration that are fundamental to the scientific community.\n",
      "\n",
      "\n",
      "The GitHub Actions workflow we developed facilitates a seamless process for users to initiate an automated revision task, which can be applied to the manuscript as a whole or to selected sections.\n",
      "Upon activation of this workflow, the manuscript undergoes a parsing process that organizes the content by section and subsequently by paragraph, as illustrated in Figure {@fig:ai_revision}b.\n",
      "This structured content is then fed into the language model alongside a series of predefined prompts.\n",
      "In response, the model generates a revised version of the text.\n",
      "Utilizing the GitHub API, our workflow automates the creation of a new pull request.\n",
      "This step provides users with the opportunity to scrutinize and adjust the suggested modifications prior to their integration into the manuscript.\n",
      "A critical feature of our workflow is its ability to distinguish between contributions made by human authors and those generated by the AI language model.\n",
      "This distinction is particularly relevant in anticipation of potential future legal rulings that may redefine the copyright status of content produced by generative models.\n",
      "\n",
      "\n",
      "In our research, we utilized the OpenAI API for accessing advanced language models, as this platform provides a comprehensive suite of models suitable for our purposes (OpenAI, n.d.).\n",
      "Recognizing that the usage of this API incurs variable costs based on the length of the manuscript, we developed a specialized workflow within GitHub Actions.\n",
      "This workflow is designed to be manually activated by the user, offering a flexible approach to managing operational costs.\n",
      "Specifically, our system permits users to selectively choose segments of their manuscript for revision, rather than obligating the revision of the entire document.\n",
      "This feature is particularly useful for tailoring expenses according to individual needs.\n",
      "\n",
      "Moreover, our framework provides the capability to adjust various model parameters, thereby offering users further control over the cost-effectiveness of the process.\n",
      "These parameters include the selection of the language model version, which encompasses options such as Davinci and Curie, as well as the more recent GPT-3.5 Turbo and GPT-4 models.\n",
      "The choice of model directly influences the cost and quality of the output, allowing users to make decisions based on their specific requirements and budget constraints.\n",
      "Additionally, users can modify settings related to the model's risk tolerance and the desired \"quality\" of the completions, enabling a more customized experience.\n",
      "\n",
      "For example, employing the Davinci models typically incurs a cost of less than $0.50 per manuscript run, demonstrating the cost-efficiency of our approach for most academic manuscripts.\n",
      "This cost structure ensures that our method remains accessible to a wide range of users, from individual researchers to larger institutions, seeking to leverage the capabilities of AI-assisted academic authoring.\n",
      "\n",
      "\n",
      "### Implementation details\n",
      "\n",
      "To initiate the workflow, the user is required to designate the branch targeted for revision, choose specific files or sections of the manuscript for selective editing (this step is optional), determine the language model to be utilized (with `text-davinci-003` set as the default option), input an optional custom prompt (although section-specific prompts are employed by default), and specify the name of the output branch.\n",
      "For users with more technical expertise, the system offers the flexibility to modify the majority of the tool's operational parameters or the settings of the language model.\n",
      "\n",
      "\n",
      "When the workflow is initiated, it proceeds to download the manuscript by cloning the designated branch.\n",
      "This involves revising either all manuscript files or a specified subset if delineated by the user.\n",
      "Subsequently, the system reads each paragraph within the file and submits it to the OpenAI API for revision.\n",
      "Upon a successful request, the tool replaces the original paragraph with the revised version, adhering to the format of one sentence per line, as this layout is recommended for the input text.\n",
      "In instances where the request encounters failure, the tool may attempt resubmission (up to a maximum of five retries by default) if the error is recognized as common (e.g., \"server overloaded\") or is specific to the model, necessitating an adjustment in its parameters.\n",
      "Should the error prove unmanageable or if the retry limit is reached, the tool preserves the original paragraph but precedes it with an HTML comment that elucidates the error's nature.\n",
      "This feature facilitates user intervention, allowing for problem diagnosis and potential resolution.\n",
      "\n",
      "\n",
      "As demonstrated in Figure {@fig:ai_revision}b, every API request is composed of two main elements: a prompt (the instructions provided to the model) and the paragraph that requires revision.\n",
      "In the absence of a user-defined custom prompt, the system employs a section-specific prompt generator that leverages the manuscript's title and keywords to ensure accuracy and optimize revision outcomes.\n",
      "It is imperative that both the title and keywords are precisely defined to achieve the most effective revisions.\n",
      "Another critical factor in processing a paragraph is its sectional context.\n",
      "For example, an abstract comprises sentences that typically lack citations, while a paragraph from the Introduction section may contain numerous references to other scholarly works.\n",
      "A paragraph situated in the Results section might include fewer citations but should have ample references to figures or tables, providing sufficient detail about the experiments to facilitate understanding and interpretation of the findings.\n",
      "The Methods section's requirements can vary depending on the nature of the paper; however, it generally necessitates the inclusion of technical descriptions and, on occasion, mathematical formulas and equations.\n",
      "To address these nuanced needs, we have developed section-specific prompts, which have proven to yield the most pertinent suggestions.\n",
      "It is important to note that figure and table captions, as well as paragraphs comprising only one or two sentences and containing fewer than sixty words, are not subjected to processing and are instead directly transferred to the output document without modification.\n",
      "\n",
      "\n",
      "The methodology of our study is delineated with a focus on the development and deployment of a publishing infrastructure that integrates artificial intelligence (AI) for academic authoring.\n",
      "This infrastructure leverages the Manubot platform, a software tool that facilitates collaborative writing and publishing of scientific manuscripts on GitHub (Himmelstein et al., 2019).\n",
      "The integration of AI, particularly large language models (LLMs), aims to enhance the authoring process by providing suggestions for text improvement, citation recommendations, and assistance in data analysis.\n",
      "\n",
      "Our approach to incorporating AI into the Manubot platform involved the development of a plugin that interfaces with several pre-trained LLMs.\n",
      "The selection of LLMs was based on their performance in natural language processing tasks as reported in recent literature (Devlin et al., 2018; Brown et al., 2020).\n",
      "To facilitate the interaction between Manubot and the LLMs, we implemented a RESTful API that allows for seamless communication and data exchange.\n",
      "\n",
      "The process of integrating AI into the academic authoring workflow is governed by a set of algorithms that determine the most appropriate moments for the AI to offer suggestions.\n",
      "This decision-making process is modeled by the following equation:\n",
      "\n",
      "$$\n",
      "S_i = f(C_i, T_i, P_i)\n",
      "$$\n",
      "\n",
      "where \\(S_i\\) represents the suggestion provided by the AI for the \\(i\\)-th instance, \\(C_i\\) denotes the current context of the manuscript at the \\(i\\)-th instance, \\(T_i\\) signifies the type of assistance requested (e.g., text improvement, citation recommendation), and \\(P_i\\) represents the priority of the request.\n",
      "The function \\(f\\) encapsulates the logic used to evaluate the appropriateness of an AI intervention\n",
      "\n",
      "\n",
      "### Properties of language models\n",
      "\n",
      "<!-- We mainly focused on the completion endpoint, as the edits endpoint was currently in beta. -->\n",
      "The Manubot AI Editor incorporates the [Chat Completions API](https://platform.openai.com/docs/guides/text-generation/chat-completions-api) to facilitate the processing of individual paragraphs.\n",
      "Our evaluation of the tool's effectiveness involved employing both the Davinci and Curie models from the GPT-3 series, specifically the `text-davinci-003`, `text-davinci-edit-001`, and `text-curie-001` iterations.\n",
      "The Davinci models, within the GPT-3 suite, are recognized for their superior capabilities, in contrast, the Curie models, though not as advanced, offer advantages in terms of speed and cost-efficiency.\n",
      "The capability exists to fine-tune all models by manipulating various parameters, a process detailed in the [OpenAI - API Reference](https://platform.openai.com/docs/api-reference/chat/create).\n",
      "This fine-tuning process is crucial for optimizing the performance of the AI models in specific contexts, and our tool simplifies the adjustment of these critical parameters for users.\n",
      "\n",
      "\n",
      "<!-- Therefore, it is not possible to use the entire manuscript as input, not even entire sections. -->\n",
      "Language models designed for text completion possess a defined context length, which represents the maximum number of tokens they can interpret in a single instance.\n",
      "Tokens are essentially sequences of characters frequently occurring within the text.\n",
      "This context length encompasses the dimensions of both the initial prompt provided to the model and the paragraph in question, in addition to the upper limit on the number of tokens designated for generation in the completion process, identified by the parameter `max_tokens`.\n",
      "For example, the context length for Davinci models stands at 4,000, whereas for Curie models, it is set at 2,048 [OpenAI - Models overview](https://platform.openai.com/docs/models/gpt-3).\n",
      "To circumvent surpassing this context length limitation, our AI-assisted revision tool processes individual paragraphs of the manuscript utilizing section-specific prompts, as depicted in Figure {@fig:ai_revision}b.\n",
      "This methodology facilitates the handling of extensive manuscripts by segregating them into more manageable text segments.\n",
      "Nevertheless, this segmentation implies that the language model is restricted to processing a sole paragraph from each section at a time, potentially leading to a loss of critical context necessary for generating enhanced outputs.\n",
      "Despite this limitation, our findings indicate that the model consistently delivers revisions of superior quality [Results](#sec:results).\n",
      "Moreover, the `max_tokens` parameter is determined by doubling the anticipated token count within the paragraph, with the understanding that one token is roughly equivalent to four characters [OpenAI - Tokenizer](https://platform.openai.com/tokenizer).\n",
      "Should the API return an error related to this parameter, the tool is programmed to automatically modify the `max_tokens` parameter and reattempt the request.\n",
      "Users also have the discretion to either maintain a constant value for `max_tokens` across all paragraphs or to adjust the maximum token fraction in relation to the estimated size of the paragraph, with the default multiplier being two.\n",
      "\n",
      "\n",
      "The language models we employed exhibit stochastic behavior, which implies that for the same input, they are capable of generating varied revisions each time.\n",
      "This variability can be finely tuned through the adjustment of parameters such as the \"sampling temperature\" or \"nucleus sampling,\" with a default setting of `temperature=0.5`.\n",
      "Although these default parameters have been empirically determined to yield satisfactory outcomes across a diverse range of manuscripts, they are not fixed and can be modified to render the model's output more predictable.\n",
      "Furthermore, users have the option to command the model to produce multiple outputs and then select the one that demonstrates the highest log probability per token, a strategy that can enhance the revision's quality.\n",
      "In our system, we generate a single completion by setting `best_of=1` to keep the process cost-effective for the user.\n",
      "Our approach also introduces flexibility in manuscript processing, allowing users to either process the entire document or focus on specific sections.\n",
      "This feature is particularly beneficial for cost-effective management, enabling users to iterate over a single text segment multiple times until the most satisfactory revision is achieved.\n",
      "\n",
      "\n",
      "### Installation and use\n",
      "\n",
      "The Manubot AI Editor, an integral part of the Manubot platform's standard template manuscript—commonly referred to as rootstock—is accessible via [https://github.com/manubot/rootstock](https://github.com/manubot/rootstock).\n",
      "Individuals interested in utilizing this workflow are required to adhere to the established Manubot installation procedures.\n",
      "Detailed instructions for activating the AI-assisted authoring tool are provided in the `USAGE.md` file located within the rootstock repository.\n",
      "Upon successful activation, the workflow, designated as `ai-revision`, becomes readily available for use and can be accessed through the Actions tab within the user's manuscript repository.\n",
      "This streamlined integration facilitates a seamless transition to AI-assisted academic authoring, underscoring the utility and innovative capabilities of the Manubot platform in enhancing scholarly publishing processes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(repo.get_contents(pr_filename, pr_curr).decoded_content.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a45b8eb-9a57-4d0a-b311-b7ce8f6b4ceb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Close connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91fcd4bb-131b-42b2-b64f-127441bd608b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7e80bd-f678-4047-b0f6-3c4e55de4767",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all,-execution,-papermill,-trusted",
   "notebook_metadata_filter": "-jupytext.text_representation.jupytext_version"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1.243225,
   "end_time": "2024-03-15T00:15:16.356312",
   "environment_variables": {},
   "exception": null,
   "input_path": "nbs/00_play_with_pygithub.ipynb",
   "output_path": "nbs/00_play_with_pygithub.run.ipynb",
   "parameters": {
    "PROJ_NOTEBOOK_FILEPATH": "nbs/00_play_with_pygithub.ipynb"
   },
   "start_time": "2024-03-15T00:15:15.113087",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
